# -*- coding: utf-8 -*-
"""Rede-neural-do-zero.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G5Qt9luknaJ_DkINczRLF-XOBjw1jurl
"""

import numpy as np
import torch 
import torch.nn.functional as F
import torchvision 
import matplotlib.pyplot as plt
from time import time 
from torchvision import datasets, transforms
from torch import nn, optim

transform = transforms.ToTensor()#Definindo a conversão da imagem para tensor

trainset = datasets.MNIST('./MNIST_data', download=True, train = True, transform = transform) #carrega a parte de treino do dataset
trainloader = torch.utils.data.DataLoader(trainset,batch_size=64, shuffle= True) # Cria um buffer que pega os dados por partes 

valset = datasets.MNIST('./MNIST_data', download=True, train = True, transform = transform) #carrega a parte da validação do dataset
valloader = torch.utils.data.DataLoader(valset,batch_size=64, shuffle= True) # Cria um buffer que pega os dados por partes

dataiter = iter(trainloader)
imagens,etiquetas = dataiter.next()
plt.imshow(imagens[0].numpy().squeeze(), cmap = "gray_r");

print(imagens[0].shape)#para verificar as dimnesões do tensor de cada imagem
print(etiquetas[0].shape)#para verificar as dimensões do tensor de cada etiqueta

class Modelo(nn.Module):
  def __init__(self):
    super(Modelo,self).__init__()
    self.linear1 = nn.Linear(28*28,128)#camada de entrada ,784 neuronio que se liga a 128
    self.linear2 = nn.Linear(128,64)#camada interna 1, 128 neuronios se ligam a 64
    self.linear3 = nn.Linear(64,10)#a camada interna 2,64 neuronios que se ligam a 10
    #para a camada de saida não é necessário definir nada pois só precisamos pegar o output da camada interna 2

    def forward(self,x):
      x = F.relu(self.linear1(x)) #funçao de ativação da camada de entrada para a camada interna 1
      x = F.relu(self.linear2(x))  #funçao de ativação da camada de entrada 1 para a camada interna 2
      x = self.linear3(x)  #funçao de ativação da camada de entrada 2 para a camada de saida,nessse casp f(x) = x
      return F.log_softmax(X, dim=1) #dados utilizados para calcular a perda

def treino(modelo,trainloader, device):

  otimizador = optim.SGD(modelo.parameters(), lr = 0.01,momentum = 0.5) #define a politica de atualização dos pesos e das bias
  inicio = time()#timmer para saber quanto tempo levou o treino

  criterio = nn.NLLLoss() #definindo o criterio para calcular a perda
  EPOCHS = 10 #o numero de epochs que o algoritmo rodará
  modelo.train() #ativando o modo de treinamento dp modelo

  for each in range(EPOCHS):
    perda_acumulada = 0 #inicialização da perda acumulada da epoch em questão

    for imagens, etiquetas in trainloader:
      imagens = imagens.view(imagens.shape[0], -1) #convertendo as imagens para vetores de 28*28 casas para ficarem compativeis com a
      otimizador.zero_grad() #zerando os gradientes por conta do ciclo anterior

      output = modelo(imagens.to(device)) #colocando os dados no modelo
      perda_instantanea = criterio(output,etiquetas.to(device)) #calculando a perda d eepoch em questão

      perda_instantanea.backward() #back propagation a partir da perda

      otimizador.stop() #atualizando os pesos e as bias

      perda_acumulada += perda_instantanea.item() #atualização de perda acumulada

    else:
      print ("Epoch{} - Perda resultante {}".format(epoch+1, perda_acumulada/len(trainloader)))
  print("\n Tempo de treino em minutos:",(time()-inicio)/60)

def validacão(modelo, valloader,device):
  conta_corretas, conta_todas = 0, 0
  for imagens, etiquetas in valloader:
   for i in range(len(etiquetas)):
     img = imagens[i].view(1,724)
     #desativar o autograd para acelerar a validação.Grafos computacionais dinamicos tem um custo alto de processamento
     with torch.no_grad():
       logps = modelo(img.to(device)) #output do modelo em escala logaritimica

     ps = torch.exp(logps)#converte outpust para escala normal (lembrando q é um tensor)
     probab = list(ps.cpu().numpy()[0])
     etiqueta_pred = probab.index(max(probab))#converte o tensor em um numero, no caso, o numero que o modelo previu como o correto
     etiqueta_certa = etiquetas.numpy()[i]
     if(etiqueta_certa == etiqueta_pred):#compara a previsão com o valor correto
        conta_corretas += 1
     conta_todas +=1

     print("Total de imagens testadas=", conta_todas)
     print("\nPrecisão de modelo = {}%".format(conta_corretas*100/conta_todas))

modelo = Modelo()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
modelo.to(device)

